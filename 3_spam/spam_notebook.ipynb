
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data\n",
      "Pulling samples from file: /media/data/knighton/data/spam_fyre.txt\n",
      "Pulling samples from file: /media/data/knighton/data/ham_fyre.txt\n",
      "Building transformers\n",
      "Transforming data\n",
      "Locating the most recent checkpoint\n",
      "Building model\n",
      "Vocab size: 223\n",
      "Compiling\n",
      "Training\n",
      "Train on 8000 samples, validate on 1000 samples\n",
      "Epoch 0\n",
      "8000/8000 [==============================] - 1s - loss: 0.6932 - acc: 0.4886 - val_loss: 7.9862 - val_acc: 0.5040\n",
      "models/5000_dense_0_256_6/epoch_0000_train_48772_val_50400.h5 models/5000_dense_0_256_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is disabled)\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "unable to create file (File accessibilty: Unable to open file)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-def7d1d2c4d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Training'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frontends\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresume_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/media/data/escherba/dev/lstm_workshop/james/spam.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data, model, num_frontends, resume_epoch, model_dir)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             show_accuracy=True)\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mEarlyTermination\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",